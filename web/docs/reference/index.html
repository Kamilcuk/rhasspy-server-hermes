<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  
  <link rel="shortcut icon" href="../img/favicon.ico">
  <title>Reference - Rhasspy</title>
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700' rel='stylesheet' type='text/css'>

  <link rel="stylesheet" href="../css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../css/theme_extra.css" type="text/css" />
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css">
  
  <script>
    // Current page data
    var mkdocs_page_name = "Reference";
    var mkdocs_page_input_path = "reference.md";
    var mkdocs_page_url = null;
  </script>
  
  <script src="../js/jquery-2.1.1.min.js" defer></script>
  <script src="../js/modernizr-2.8.3.min.js" defer></script>
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script> 
  
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
      <div class="wy-side-nav-search">
        <a href=".." class="icon icon-home"> Rhasspy</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
	<ul class="current">
	  
          
            <li class="toctree-l1">
		
    <a class="" href="..">Home</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../installation/">Installation</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../services/">Services</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../tutorials/">Tutorials</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../usage/">Usage</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../profiles/">Profiles</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../training/">Training</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../hardware/">Hardware</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../audio-input/">Audio Input</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../audio-output/">Audio Output</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../wake-word/">Wake Word</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../command-listener/">Command Listener</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../speech-to-text/">Speech to Text</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../intent-recognition/">Intent Recognition</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../intent-handling/">Intent Handling</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../text-to-speech/">Text to Speech</a>
	    </li>
          
            <li class="toctree-l1 current">
		
    <a class="current" href="./">Reference</a>
    <ul class="subnav">
            
    <li class="toctree-l2"><a href="#reference">Reference</a></li>
    
        <ul>
        
            <li><a class="toctree-l3" href="#supported-languages">Supported Languages</a></li>
        
            <li><a class="toctree-l3" href="#mqtt-api">MQTT API</a></li>
        
            <li><a class="toctree-l3" href="#http-api">HTTP API</a></li>
        
            <li><a class="toctree-l3" href="#websocket-api">Websocket API</a></li>
        
            <li><a class="toctree-l3" href="#profile-settings">Profile Settings</a></li>
        
            <li><a class="toctree-l3" href="#command-line-tools">Command Line Tools</a></li>
        
        </ul>
    

    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../development/">Development</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../license/">License</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../about/">About</a>
	    </li>
          
        </ul>
      </div>
      &nbsp;
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="..">Rhasspy</a>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="..">Docs</a> &raquo;</li>
    
      
    
    <li>Reference</li>
    <li class="wy-breadcrumbs-aside">
      
    </li>
  </ul>
  <hr/>
</div>
          <div role="main">
            <div class="section">
              
                <h1 id="reference">Reference</h1>
<ul>
<li><a href="#supported-languages">Supported Languages</a></li>
<li><a href="#mqtt-api">MQTT API</a></li>
<li><a href="#http-api">HTTP API</a></li>
<li><a href="#websocket-api">Websocket API</a></li>
<li><a href="#profile-settings">Profile Settings</a></li>
<li><a href="#command-line-tools">Command Line Tools</a></li>
</ul>
<h2 id="supported-languages">Supported Languages</h2>
<p>The table below lists which components and compatible with Rhasspy's supported languages.</p>
<table>
<thead>
<tr>
<th>Category</th>
<th>Name</th>
<th>Offline?</th>
<th>en</th>
<th>de</th>
<th>es</th>
<th>fr</th>
<th>it</th>
<th>nl</th>
<th>ru</th>
<th>el</th>
<th>hi</th>
<th>zh</th>
<th>vi</th>
<th>pt</th>
<th>sv</th>
<th>ca</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Wake Word</strong></td>
<td><a href="../wake-word/#pocketsphinx">pocketsphinx</a></td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td><a href="../wake-word/#porcupine">porcupine</a></td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td><a href="../wake-word/#snowboy">snowboy</a></td>
<td><em>requires account</em></td>
<td>&#x2713;</td>
<td>&bull;</td>
<td>&bull;</td>
<td>&bull;</td>
<td>&bull;</td>
<td>&bull;</td>
<td>&bull;</td>
<td>&bull;</td>
<td>&bull;</td>
<td>&bull;</td>
<td>&bull;</td>
<td>&bull;</td>
<td>&bull;</td>
<td>&bull;</td>
</tr>
<tr>
<td></td>
<td><a href="../wake-word/#mycroft-precise">precise</a></td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&bull;</td>
<td>&bull;</td>
<td>&bull;</td>
<td>&bull;</td>
<td>&bull;</td>
<td>&bull;</td>
<td>&bull;</td>
<td>&bull;</td>
<td>&bull;</td>
<td>&bull;</td>
<td>&bull;</td>
<td>&bull;</td>
<td>&bull;</td>
</tr>
<tr>
<td><strong>Speech to Text</strong></td>
<td><a href="../speech-to-text/#pocketsphinx">pocketsphinx</a></td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td></td>
<td>&#x2713;</td>
<td></td>
<td>&#x2713;</td>
</tr>
<tr>
<td></td>
<td><a href="../speech-to-text/#kaldi">kaldi</a></td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td></td>
<td>&#x2713;</td>
<td></td>
<td>&#x2713;</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>&#x2713;</td>
<td></td>
<td>&#x2713;</td>
<td></td>
</tr>
<tr>
<td><strong>Intent Recognition</strong></td>
<td><a href="../intent-recognition/#fsticuffs">fsticuffs</a></td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
</tr>
<tr>
<td></td>
<td><a href="../intent-recognition/#fuzzywuzzy">fuzzywuzzy</a></td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
</tr>
<tr>
<td></td>
<td><a href="../intent-recognition/#mycroft-adapt">adapt</a></td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
</tr>
<tr>
<td></td>
<td><a href="../intent-recognition/#flair">flair</a></td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td></td>
<td>&#x2713;</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>&#x2713;</td>
<td></td>
<td>&#x2713;</td>
</tr>
<tr>
<td></td>
<td><a href="../intent-recognition/#rasanlu">rasaNLU</a></td>
<td><em>needs extra software</em></td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
</tr>
<tr>
<td><strong>Text to Speech</strong></td>
<td><a href="../text-to-speech/#espeak">espeak</a></td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
</tr>
<tr>
<td></td>
<td><a href="../text-to-speech/#flite">flite</a></td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>&#x2713;</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td><a href="../text-to-speech/#picotts">picotts</a></td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td><a href="../text-to-speech/#marytts">marytts</a></td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td></td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td></td>
<td>&#x2713;</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td><a href="../text-to-speech/#google-wavenet">wavenet</a></td>
<td></td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td></td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td></td>
<td>&#x2713;</td>
<td>&#x2713;</td>
<td></td>
</tr>
</tbody>
</table>
<p>&bull; - yes, but requires training/customization</p>
<h2 id="mqtt-api">MQTT API</h2>
<p>Rhasspy implements a superset of the <a href="https://docs.snips.ai/reference/hermes">Hermes protocol</a> in <a href="https://github.com/rhasspy/rhasspy-hermes">rhasspy-hermes</a> for the following components:</p>
<ul>
<li><a href="#audio-server">Audio Server</a></li>
<li><a href="#automated-speech-recognition">Automated Speech Recognition</a></li>
<li><a href="#dialogue-manager">Dialogue Manager</a></li>
<li><a href="#grapheme-to-phoneme">Grapheme to Phoneme</a></li>
<li><a href="#hotword-detection">Hotword Detection</a></li>
<li><a href="#intent-handling">Intent Handling</a></li>
<li><a href="#natural-language-understanding">Natural Language Understanding</a></li>
<li><a href="#text-to-speech">Text to Speech</a></li>
</ul>
<h3 id="audio-server">Audio Server</h3>
<p>Messages for <a href="../audio-input/">audio input</a> and <a href="../audio-output/">audio output</a>.</p>
<ul>
<li><a id="audioserver_audioframe"><tt>hermes/audioServer/&lt;siteId&gt;/audioFrame</tt></a> (binary)<ul>
<li>Chunk of WAV audio data</li>
<li><code>wav_bytes: bytes</code> - WAV data to play (<strong>message payload</strong>)</li>
<li><code>siteId: string</code> - Hermes site ID (part of topic)</li>
</ul>
</li>
<li><a id="audioserver_playbytes"><tt>hermes/audioServer/&lt;siteId&gt;/playBytes/&lt;requestId&gt;</tt></a> (JSON)<ul>
<li>Play WAV data</li>
<li><code>wav_bytes: bytes</code> - WAV data to play (message payload)</li>
<li><code>requestId: string</code> - unique ID for request (part of topic)</li>
<li><code>siteId: string</code> - Hermes site ID (part of topic)</li>
<li>Response(s)<ul>
<li><a href="#audioserver_playfinished"><code>hermes/audioServer/&lt;siteId&gt;/playFinished</code></a> (JSON)</li>
</ul>
</li>
</ul>
</li>
<li><a id="audioserver_playfinished"><tt>hermes/audioServer/&lt;siteId&gt;/playFinished</tt></a><ul>
<li>Indicates that audio has finished playing</li>
<li>Response to <a href="#audioserver_playbytes"><code>hermes/audioServer/&lt;siteId&gt;/playBytes/&lt;requestId&gt;</code></a></li>
<li><code>siteId: string</code> - Hermes site ID (part of topic)</li>
<li><code>id: string = ""</code> - <code>requestId</code> from request message</li>
</ul>
</li>
</ul>
<h3 id="automated-speech-recognition">Automated Speech Recognition</h3>
<p>Messages for <a href="../speech-to-text/">speech to text</a>.</p>
<ul>
<li><a id="asr_toggleon"><tt>hermes/asr/toggleOn</tt></a> (JSON)<ul>
<li>Enables ASR system</li>
<li><code>siteId: string = "default"</code> - Hermes site ID</li>
</ul>
</li>
<li><a id="asr_toggleoff"><tt>hermes/asr/toggleOff</tt></a> (JSON)<ul>
<li>Disables ASR system</li>
<li><code>siteId: string = "default"</code> - Hermes site ID</li>
</ul>
</li>
<li><a id="asr_startlistening"><tt>hermes/asr/startListening</tt></a> (JSON)<ul>
<li>Tell ASR system to start recording/transcribing</li>
<li><code>siteId: string = "default"</code> - Hermes site ID</li>
<li><code>sessionId: string = ""</code> - current session ID</li>
</ul>
</li>
<li><a id="asr_stoplistening"><tt>hermes/asr/stopListening</tt></a> (JSON)<ul>
<li>Tell ASR system to stop recording</li>
<li>Emits <a href="#asr_textcaptured"><code>textCaptured</code></a> if silence has was not detected earlier</li>
<li><code>siteId: string = "default"</code> - Hermes site ID</li>
<li><code>sessionId: string = ""</code> - current session ID</li>
</ul>
</li>
<li><a id="asr_textcaptured"><tt>hermes/asr/textCaptured</tt></a> (JSON)<ul>
<li>Successful transcription, sent either when silence is detected or on <a href="#asr_stoplistening"><code>stopListening</code></a></li>
<li><code>text: string</code> - transcription text</li>
<li><code>likelihood: float</code> - confidence from ASR system</li>
<li><code>seconds: float</code> - transcription time in seconds</li>
<li><code>siteId: string = "default"</code> - Hermes site ID</li>
<li><code>sessionId: string = ""</code> - current session ID</li>
</ul>
</li>
<li><a id="asr_error"><tt>hermes/error/asr</tt></a> (JSON)<ul>
<li>Sent when an error occurs in the ASR system</li>
<li><code>error: string</code> - description of the error</li>
<li><code>context: string</code> - system-defined context of the error</li>
<li><code>siteId: string = "default"</code> - Hermes site ID</li>
<li><code>sessionId: string = ""</code> - current session ID</li>
</ul>
</li>
<li><a id="asr_train"><tt>rhasspy/asr/&lt;siteId&gt;/train</tt></a> (JSON, Rhasspy only)<ul>
<li>Instructs the ASR system to re-train</li>
<li><code>id: string</code> - unique ID for request (copied to <a href="#asr_trainsuccess"><code>trainSuccess</code></a>)</li>
<li><code>graph_dict: object</code> - intent graph from <a href="https://github.com/rhasspy/rhasspy-nlu">rhasspy-nlu</a> encoded as a JSON object</li>
<li><code>siteId: string</code> - Hermes site ID (part of topic)</li>
<li>Response(s)<ul>
<li><a href="#asr_trainsuccess"><code>rhasspy/asr/&lt;siteId&gt;/trainSuccess</code></a></li>
<li><a href="#asr_error"><code>hermes/error/asr</code></a></li>
</ul>
</li>
</ul>
</li>
<li><a id="asr_trainsuccess"><tt>rhasspy/asr/&lt;siteId&gt;/trainSuccess</tt></a> (JSON, Rhasspy only)<ul>
<li>Indicates that training was successful</li>
<li><code>id: string</code> - unique ID from request (copied from <a href="#asr_train"><code>train</code></a>)</li>
<li><code>siteId: string</code> - Hermes site ID (part of topic)</li>
<li>Response to <a href="#asr_train"><code>rhasspy/asr/&lt;siteId&gt;/train</code></a></li>
</ul>
</li>
<li><a id="asr_audiocaptured"><tt>rhasspy/asr/&lt;siteId&gt;/&lt;sessionId&gt;/audioCaptured</tt></a> (binary, Rhasspy only)<ul>
<li>WAV audio data captured by ASR session</li>
<li><code>siteId: string</code> - Hermes site ID (part of topic)</li>
<li><code>sessionId: string</code> - current session ID (part of topic)</li>
<li>Only sent if <code>sendAudioCaptured = true</code> in <a href="#asr_startlistening"><code>startListening</code></a></li>
</ul>
</li>
</ul>
<h3 id="dialogue-manager">Dialogue Manager</h3>
<p>Messages for managing dialogue sessions. These can be initiated by a hotword <a href="#hotword_detected"><code>detected</code></a> message (or <a href="#api_listen_for_command"><code>/api/listen-for-command</code></a>), and manually with a <a href="#dialoguemanager_startsession"><code>startSession</code></a> message (or <a href="#api_start_recording"><code>/api/start-recording</code></a>).</p>
<ul>
<li><a id="dialoguemanager_startsession"><tt>hermes/dialogueManager/startSession</tt></a> (JSON)<ul>
<li>Starts a new dialogue session (done automatically on hotword <a href="#hotword_detected"><code>detected</code></a>)</li>
<li><code>init: object</code> - JSON object with one of two forms:<ul>
<li>Action<ul>
<li><code>type: string = "action"</code> - required</li>
<li><code>canBeEnqueued: bool</code> - true if session can be queued if there is already one (required)</li>
<li><code>text: string = ""</code> - sentence to speak using <a href="#text-to-speech">text to speech</a></li>
<li><code>intentFilter: [string] = null</code> - valid intent names (<code>null</code> means all) </li>
<li><code>sendIntentNotRecognized: bool = false</code> - send <a href="#dialoguemanager_intentnotrecognized"><code>hermes/dialogueManager/intentNotRecognized</code></a> if <a href="../intent-recognition/">intent recognition</a> fails</li>
</ul>
</li>
<li>Notification<ul>
<li><code>type: string = "notification"</code> - required</li>
<li><code>text: string</code> - sentence to speak using <a href="#text-to-speech">text to speech</a> (required)</li>
</ul>
</li>
</ul>
</li>
<li><code>siteId: string = "default"</code> - Hermes site ID</li>
<li><code>customData: string = ""</code> - user-defined data passed to subsequent session messages</li>
<li>Response(s)<ul>
<li><a href="#dialoguemanager_sessionstarted"><code>hermes/dialogueManager/sessionStarted</code></a></li>
<li><a href="#dialoguemanager_sessionqueued"><code>hermes/dialogueManager/sessionQueued</code></a></li>
</ul>
</li>
</ul>
</li>
<li><a id="dialoguemanager_sessionstarted"><tt>hermes/dialogueManager/sessionStarted</tt></a> (JSON)<ul>
<li>Indicates a session has started</li>
<li><code>siteId: string = "default"</code> - Hermes site ID</li>
<li><code>sessionId: string = ""</code> - current session ID</li>
<li><code>customData: string = ""</code> - user-defined data (copied from <a href="#dialoguemanager_startsession"><code>startSession</code></a>)</li>
<li>Response to [<code>hermes/dialogueManager/startSession</code>]</li>
</ul>
</li>
<li><a id="dialoguemanager_sessionqueued"><tt>hermes/dialogueManager/sessionQueued</tt></a> (JSON)<ul>
<li>Indicates a session has been queued (only when <code>init.canBeEnqueued = true</code> in <a href="#dialoguemanager_startsession"><code>startSession</code></a>)</li>
<li><code>siteId: string = "default"</code> - Hermes site ID</li>
<li><code>sessionId: string = ""</code> - current session ID</li>
<li><code>customData: string = ""</code> - user-defined data (copied from <a href="#dialoguemanager_startsession"><code>startSession</code></a>)</li>
<li>Response to [<code>hermes/dialogueManager/startSession</code>]</li>
</ul>
</li>
<li><a id="dialoguemanager_continuesession"><tt>hermes/dialogueManager/continueSession</tt></a> (JSON)<ul>
<li>Requests that a session be continued after an <a href="#nlu_intent"><code>intent</code></a> has been recognized</li>
<li><code>sessionId: string</code> - current session ID (required)</li>
<li><code>customData: string = ""</code> - user-defined data (overrides session <code>customData</code> if not empty)</li>
<li><code>text: string = ""</code> - sentence to speak using <a href="#text-to-speech">text to speech</a></li>
<li><code>intentFilter: [string] = null</code> - valid intent names (<code>null</code> means all) </li>
<li><code>sendIntentNotRecognized: bool = false</code> - send <a href="#dialoguemanager_intentnotrecognized"><code>hermes/dialogueManager/intentNotRecognized</code></a> if <a href="../intent-recognition/">intent recognition</a> fails</li>
</ul>
</li>
<li><a id="dialoguemanager_endsession"><tt>hermes/dialogueManager/endSession</tt></a> (JSON)<ul>
<li>Requests that a session be terminated nominally</li>
<li><code>sessionId: string</code> - current session ID (required)</li>
<li><code>customData: string = ""</code> - user-defined data (overrides session <code>customData</code> if not empty)</li>
</ul>
</li>
<li><a id="dialoguemanager_sessionended"><tt>hermes/dialogueManager/sessionEnded</tt></a> (JSON)<ul>
<li>Indicates a session has terminated</li>
<li><code>termination: string</code> reason for termination (required), one of:<ul>
<li>nominal</li>
<li>abortedByUser</li>
<li>intentNotRecognized</li>
<li>timeout</li>
<li>error</li>
</ul>
</li>
<li><code>siteId: string = "default"</code> - Hermes site ID</li>
<li><code>sessionId: string = ""</code> - current session ID</li>
<li><code>customData: string = ""</code> - user-defined data (copied from <a href="#dialoguemanager_startsession"><code>startSession</code></a>)</li>
<li>Response to <a href="#dialoguemanager_endsession"><code>hermes/dialogueManager/endSession</code></a> or other reasons for a session termination</li>
</ul>
</li>
<li><a id="dialoguemanager_intentnotrecognized"><tt>hermes/dialogueManager/intentNotRecognized</tt></a> (JSON)<ul>
<li>Sent when <a href="../intent-recognition/">intent recognition</a> fails during a session (only when <code>init.sendIntentNotRecognized = true</code> in <a href="#dialoguemanager_startsession"><code>startSession</code></a>)</li>
<li><code>input: string</code> input to NLU system (required)</li>
<li><code>siteId: string = "default"</code> - Hermes site ID</li>
<li><code>sessionId: string = ""</code> - current session ID</li>
<li><code>customData: string = ""</code> - user-defined data (copied from <a href="#dialoguemanager_startsession"><code>startSession</code></a>)</li>
</ul>
</li>
</ul>
<h3 id="grapheme-to-phoneme">Grapheme to Phoneme</h3>
<p>Messages for looking up <a href="../training/#custom-words">word pronunciations</a>. See also the <a href="#api_lookup"><code>/api/lookup</code></a> HTTP endpoint.</p>
<p>Words are usually looked up from a <a href="https://cmusphinx.github.io/wiki/tutorialdict/">phonetic dictionary</a> included with the ASR system. The current <a href="../services/#speech-to-text">speech to text</a> services handle these messages.</p>
<ul>
<li><a id="g2p_pronounce"><tt>rhasspy/g2p/pronounce</tt></a> (JSON, Rhasspy only)<ul>
<li>Requests phonetic pronunciations of words</li>
<li><code>id: string = ""</code> - unique ID for request (copied to <a href="#g2p_phonemes"><code>phonemes</code></a>)</li>
<li><code>words: [string]</code> - words to pronounce (required)</li>
<li><code>numGuesses: int = 5</code> - number of guesses if not in dictionary</li>
<li><code>siteId: string = "default"</code> - Hermes site ID</li>
<li><code>sessionId: string = ""</code> - current session ID</li>
<li>Response(s)<ul>
<li><a href="#g2p_phonemes"><code>rhasspy/g2p/phonemes</code></a></li>
</ul>
</li>
</ul>
</li>
<li><a id="g2p_phonemes"><tt>rhasspy/g2p/phonemes</tt></a> (JSON, Rhasspy only)<ul>
<li>Phonetic pronunciations of words, either from a dictionary or grapheme-to-phoneme model</li>
<li><code>wordPhonemes: [object]</code> - phonetic pronunciations (required), keyed by word, values are:<ul>
<li><code>phonemes: [string]</code> - phonemes for word (key)</li>
<li><code>guessed: bool</code> - true if pronunciation came from a grapheme-to-phoneme model</li>
</ul>
</li>
<li><code>id: string = ""</code> - unique ID for request (copied from <a href="#g2p_pronounce"><code>pronounce</code></a>)</li>
<li><code>siteId: string = "default"</code> - Hermes site ID</li>
<li><code>sessionId: string = ""</code> - current session ID</li>
<li>Response to <a href="#g2p_pronounce"><code>rhasspy/g2p/pronounce</code></a></li>
</ul>
</li>
<li><a id="g2p_error"><tt>rhasspy/error/g2p</tt></a> (JSON, Rhasspy only)<ul>
<li>Sent when an error occurs in the G2P system</li>
<li><code>error: string</code> - description of the error</li>
<li><code>context: string</code> - system-defined context of the error</li>
<li><code>siteId: string = "default"</code> - Hermes site ID</li>
<li><code>sessionId: string = ""</code> - current session ID</li>
</ul>
</li>
</ul>
<h3 id="hotword-detection">Hotword Detection</h3>
<p>Messages for <a href="../wake-word/">wake word detection</a>. See also the <a href="#api_listen_for_wake"><code>/api/listen-for-wake</code></a> HTTP endpoint and the <a href="#api_events_wake"><code>/api/events/wake</code></a> Websocket endpoint.</p>
<ul>
<li><a id="hotword_toggleon"><tt>hermes/hotword/toggleOn</tt></a> (JSON)<ul>
<li>Enables hotword detection</li>
<li><code>siteId: string = "default"</code> - Hermes site ID</li>
</ul>
</li>
<li><a id="hotword_toggleoff"><tt>hermes/hotword/toggleOff</tt></a> (JSON)<ul>
<li>Disables hotword detection</li>
<li><code>siteId: string = "default"</code> - Hermes site ID</li>
</ul>
</li>
<li><a id="hotword_detected"><tt>hermes/hotword/&lt;wakewordId&gt;/detected</tt></a> (JSON)<ul>
<li>Indicates a hotword was successfully detected</li>
<li><code>wakewordId: string</code> - wake word ID (part of topic)</li>
<li><code>modelId: string</code> - ID of wake word model used (service specific)</li>
<li><code>modelVersion: string = ""</code> - version of wake word model used (service specific)</li>
<li><code>modelType: string = "personal"</code> - type of wake word model used (service specific)</li>
<li><code>currentSensitivity: float = 1.0</code> - sensitivity of wake word detection (service specific)</li>
<li><code>siteId: string = "default"</code> - Hermes site ID</li>
<li><code>sessionId: string = ""</code> - current session ID (Rhasspy only)</li>
</ul>
</li>
<li><a id="hotword_error"><tt>hermes/error/hotword</tt></a> (JSON, Rhasspy only)<ul>
<li>Sent when an error occurs in the hotword system</li>
<li><code>error: string</code> - description of the error</li>
<li><code>context: string</code> - system-defined context of the error</li>
<li><code>siteId: string = "default"</code> - Hermes site ID</li>
</ul>
</li>
</ul>
<h3 id="intent-handling">Intent Handling</h3>
<p>Messages for <a href="../intent-handling/">intent handling</a>.</p>
<ul>
<li><a id="handle_toggleon"><tt>rhasspy/handle/toggleOn</tt></a> (JSON, Rhasspy only)<ul>
<li>Enables intent handling</li>
<li><code>siteId: string = "default"</code> - Hermes site ID</li>
</ul>
</li>
<li><a id="handle_toggleoff"><tt>rhasspy/handle/toggleOff</tt></a> (JSON, Rhasspy only)<ul>
<li>Disables intent handling</li>
<li><code>siteId: string = "default"</code> - Hermes site ID</li>
</ul>
</li>
</ul>
<h3 id="natural-language-understanding">Natural Language Understanding</h3>
<ul>
<li><a id="nlu_query"><tt>hermes/nlu/query</tt></a> (JSON)<ul>
<li>Request an intent to be recognized from text</li>
<li><code>input: string</code> - text to recognize intent from (required)</li>
<li><code>intentFilter: [string] = null</code> - valid intent names (<code>null</code> means all) </li>
<li><code>id: string = ""</code> - unique id for request (copied to response messages)</li>
<li><code>siteId: string = "default"</code> - Hermes site ID</li>
<li><code>sessionId: string = ""</code> - current session ID</li>
<li>Response(s)<ul>
<li><a href="#nlu_intent"><code>hermes/nlu/intent/&lt;intentName&gt;</code></a></li>
<li><a href="#nlu_intentnotrecognized"><code>hermes/nlu/intentNotRecognized</code></a></li>
</ul>
</li>
</ul>
</li>
<li><a id="nlu_intent"><tt>hermes/nlu/intent/&lt;intentName&gt;</tt></a> (JSON)<ul>
<li>Sent when an intent was successfully recognized</li>
<li><code>input: string</code> - text from query (required)</li>
<li><code>intent: object</code> - details of recognized intent (required)<ul>
<li><code>intentName: string</code> - name of intent (required)</li>
<li><code>confidenceScore: float</code> - confidence from NLU system for this intent (required)</li>
</ul>
</li>
<li><code>slots: [object] = []</code> - details of named entities, list of:<ul>
<li><code>entity: string</code> - name of entity (required)</li>
<li><code>slotName: string</code> - name of slot (required)</li>
<li><code>confidence: float</code> - confidence from NLU system for this slot (required)</li>
<li><code>raw_value: string</code> - entity value <strong>without</strong> <a href="../training/#substitutions">substitutons</a> (required)</li>
<li><code>value: string</code> - entity value with <a href="../training/#substitutions">substitutons</a> (required)</li>
<li><code>range: object = null</code> - indexes of entity value in text<ul>
<li><code>start: int</code> - start index</li>
<li><code>end: int</code> - end index (exclusive)</li>
</ul>
</li>
</ul>
</li>
<li><code>id: string = ""</code> - unique id for request (copied from <a href="#nlu_query"><code>query</code></a>)</li>
<li><code>siteId: string = "default"</code> - Hermes site ID</li>
<li><code>sessionId: string = ""</code> - current session ID</li>
<li><code>customData: string = ""</code> - user-defined data (copied from <a href="#dialoguemanager_startsession"><code>startSession</code></a>)</li>
<li><code>asrTokens: [string] = []</code> - tokens from <a href="#asr_textcaptured">transcription</a></li>
<li><code>asrConfidence: float = 1.0</code> - confidence from ASR system for input text</li>
<li>Response to <a href="#nlu_query"><code>hermes/nlu/query</code></a></li>
</ul>
</li>
<li><a id="nlu_intentnotrecognized"><tt>hermes/nlu/intentNotRecognized</tt></a> (JSON)<ul>
<li>Sent when <a href="../intent-recognition/">intent recognition</a> fails</li>
<li><code>input: string</code> - text from query (required)</li>
<li><code>id: string = ""</code> - unique id for request (copied from <a href="#nlu_query"><code>query</code></a>)</li>
<li><code>siteId: string = "default"</code> - Hermes site ID</li>
<li><code>sessionId: string = ""</code> - current session ID</li>
<li>Response to <a href="#nlu_query"><code>hermes/nlu/query</code></a></li>
</ul>
</li>
<li><a id="nlu_error"><tt>hermes/error/nlu</tt></a> (JSON)<ul>
<li>Sent when an error occurs in the NLU system</li>
<li><code>error: string</code> - description of the error</li>
<li><code>context: string</code> - system-defined context of the error</li>
<li><code>siteId: string = "default"</code> - Hermes site ID</li>
<li><code>sessionId: string = ""</code> - current session ID</li>
</ul>
</li>
<li><a id="nlu_train"><tt>rhasspy/nlu/&lt;siteId&gt;/train</tt></a> (JSON, Rhasspy only)<ul>
<li>Instructs the NLU system to re-train</li>
<li><code>id: string</code> - unique ID for request (copied to <a href="#nlu_trainsuccess"><code>trainSuccess</code></a>)</li>
<li><code>graph_dict: object</code> - intent graph from <a href="https://github.com/rhasspy/rhasspy-nlu">rhasspy-nlu</a> encoded as a JSON object</li>
<li><code>siteId: string</code> - Hermes site ID (part of topic)</li>
<li>Response(s)<ul>
<li><a href="#nlu_trainsuccess"><code>rhasspy/nlu/&lt;siteId&gt;/trainSuccess</code></a></li>
<li><a href="#nlu_error"><code>hermes/error/nlu</code></a></li>
</ul>
</li>
</ul>
</li>
<li><a id="nlu_trainsuccess"><tt>rhasspy/nlu/&lt;siteId&gt;/trainSuccess</tt></a> (JSON, Rhasspy only)<ul>
<li>Indicates that training was successful</li>
<li><code>id: string</code> - unique ID from request (copied from <a href="#nlu_train"><code>train</code></a>)</li>
<li><code>siteId: string</code> - Hermes site ID (part of topic)</li>
<li>Response to <a href="#nlu_train"><code>rhasspy/nlu/&lt;siteId&gt;/train</code></a></li>
</ul>
</li>
</ul>
<h3 id="text-to-speech">Text to Speech</h3>
<ul>
<li><a id="tts_say"><tt>hermes/tts/say</tt></a> (JSON)<ul>
<li>Generate spoken audio for a sentence using the configured text to speech system</li>
<li>Automatically sends <a href="#audioserver_playbytes"><code>playBytes</code></a><ul>
<li><code>playBytes.requestId = say.id</code></li>
</ul>
</li>
<li><code>text: string</code> - sentence to speak (required)</li>
<li><code>lang: string = ""</code> - language for TTS system</li>
<li><code>id: string = ""</code> - unique ID for request (copied to <code>sayFinished</code>)</li>
<li><code>siteId: string = "default"</code> - Hermes site ID</li>
<li><code>sessionId: string = ""</code> - current session ID</li>
<li>Response(s)<ul>
<li><a href="#tts_sayfinished"><code>hermes/tts/sayFinished</code></a> (JSON)</li>
</ul>
</li>
</ul>
</li>
<li><a id="tts_sayfinished"><tt>hermes/tts/sayFinished</tt></a> (JSON)<ul>
<li>Indicates that the text to speech system has finished generating audio</li>
<li><code>id: string = ""</code> - unique ID for request (copied from <code>say</code>)</li>
<li><code>siteId: string = "default"</code> - Hermes site ID</li>
<li>Response to <a href="#tts_say"><code>hermes/tts/say</code></a></li>
<li>Listen for <a href="#audioserver_playfinished"><code>playFinished</code></a> to determine when audio is finished playing<ul>
<li><code>playFinished.id = sayFinished.id</code></li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="http-api">HTTP API</h2>
<p>Rhasspy's HTTP endpoints are documented below. You can also visit <code>/api/</code> in your Rhasspy server (note the final slash) to try out each endpoint.</p>
<p>Application authors may want to use the <a href="https://pypi.org/project/rhasspy-client/">rhasspy-client</a>, which provides a high-level interface to a remote Rhasspy server.</p>
<h3 id="endpoints">Endpoints</h3>
<ul>
<li><a id="api_custom_words"><tt>/api/custom-words</tt></a><ul>
<li>GET custom word dictionary as plain text, or POST to overwrite it</li>
<li>See <code>custom_words.txt</code> in your profile directory</li>
</ul>
</li>
<li><code>/api/download-profile</code><ul>
<li>Force Rhasspy to re-download profile</li>
</ul>
</li>
<li><a id="api_listen_for_command"><tt>/api/listen-for-command</tt></a><ul>
<li>POST to wake Rhasspy up and start listening for a voice command</li>
<li>Returns intent JSON when command is finished</li>
<li><code>?nohass=true</code> - stop Rhasspy from handling the intent</li>
<li><code>?timeout=&lt;seconds&gt;</code> - override default command timeout</li>
<li><code>?entity=&lt;entity&gt;&amp;value=&lt;value&gt;</code> - set custom entity/value in recognized intent</li>
</ul>
</li>
<li><a id="api_listen_for_wake"><tt>/api/listen-for-wake</tt></a><ul>
<li>POST "on" to have Rhasspy listen for a wake word</li>
<li>POST "off" to disable wake word</li>
</ul>
</li>
<li><a id="api_lookup"><tt>/api/lookup</tt></a><ul>
<li>POST word as plain text to look up or guess pronunciation</li>
<li><code>?n=&lt;number&gt;</code> - return at most <code>n</code> guessed pronunciations</li>
</ul>
</li>
<li><a id="/api/microphones"><tt>/api/microphones</tt></a><ul>
<li>GET list of available microphones</li>
</ul>
</li>
<li><a id="api_phonemes"><tt>/api/phonemes</tt></a><ul>
<li>GET example phonemes from speech recognizer for your profile</li>
<li>See <code>phoneme_examples.txt</code> in your profile directory</li>
</ul>
</li>
<li><a id="api_play_wav"><tt>/api/play-wav</tt></a><ul>
<li>POST to play WAV data</li>
</ul>
</li>
<li><a id="api_profile"><tt>/api/profile</tt></a><ul>
<li>GET the JSON for your profile, or POST to overwrite it</li>
<li><code>?layers=profile</code> to only see settings different from <code>defaults.json</code></li>
<li>See <code>profile.json</code> in your profile directory</li>
</ul>
</li>
<li><a id="api_restart"><tt>/api/restart</tt></a><ul>
<li>Restart Rhasspy server</li>
</ul>
</li>
<li><a id="api_sentences"><tt>/api/sentences</tt></a><ul>
<li>GET voice command templates or POST to overwrite</li>
<li>Set <code>Accept: application/json</code> to GET JSON with all sentence files</li>
<li>Set <code>Content-Type: application/json</code> to POST JSON with sentences for multiple files</li>
<li>See <code>sentences.ini</code> and <code>intents</code> directory in your profile</li>
</ul>
</li>
<li><a id="api_slots"><tt>/api/slots</tt></a><ul>
<li>GET slot values as JSON or POST to add to/overwrite them</li>
<li><code>?overwrite_all=true</code> to clear slots in JSON before writing</li>
</ul>
</li>
<li><a id="api_speakers"><tt>/api/speakers</tt></a><ul>
<li>GET list of available audio output devices</li>
</ul>
</li>
<li><a id="api_speech_to_intent"><tt>/api/speech-to-intent</tt></a><ul>
<li>POST a WAV file and have Rhasspy process it as a voice command</li>
<li>Returns intent JSON when command is finished</li>
<li><code>?nohass=true</code> - stop Rhasspy from handling the intent</li>
</ul>
</li>
<li><a id="api_speech_to_text"><tt>/api/speech-to-text</tt></a><ul>
<li>POST a WAV file and have Rhasspy return the text transcription</li>
<li>Set <code>Accept: application/json</code> to receive JSON with more details</li>
<li><code>?noheader=true</code> - send raw 16-bit 16Khz mono audio without a WAV header</li>
</ul>
</li>
<li><a id="api_start_recording"><tt>/api/start-recording</tt></a><ul>
<li>POST to have Rhasspy start recording a voice command</li>
</ul>
</li>
<li><a id="api_stop_recording"><tt>/api/stop-recording</tt></a><ul>
<li>POST to have Rhasspy stop recording and process recorded data as a voice command</li>
<li>Returns intent JSON when command has been processed</li>
<li><code>?nohass=true</code> - stop Rhasspy from handling the intent</li>
</ul>
</li>
<li><a id="api_test_microphones"><tt>/api/test-microphones</tt></a><ul>
<li>GET list of available microphones and if they're working</li>
</ul>
</li>
<li><a id="api_text_to_intent"><tt>/api/text-to-intent</tt></a><ul>
<li>POST text and have Rhasspy process it as command</li>
<li>Returns intent JSON when command has been processed</li>
<li><code>?nohass=true</code> - stop Rhasspy from handling the intent</li>
</ul>
</li>
<li><a id="api_text_to_speech"><tt>/api/text-to-speech</tt></a><ul>
<li>POST text and have Rhasspy speak it</li>
<li><code>?play=false</code> - get WAV data instead of having Rhasspy speak</li>
<li><code>?voice=&lt;voice&gt;</code> - override default TTS voice</li>
<li><code>?language=&lt;language&gt;</code> - override default TTS language or locale</li>
<li><code>?repeat=true</code> - have Rhasspy repeat the last sentence it spoke</li>
</ul>
</li>
<li><a id="api_train"><tt>/api/train</tt></a><ul>
<li>POST to re-train your profile</li>
</ul>
</li>
<li><a id="api_unknown_words"><tt>/api/unknown-words</tt></a><ul>
<li>GET words that Rhasspy doesn't know in your sentences</li>
<li>See <code>unknown_words.txt</code> in your profile directory</li>
</ul>
</li>
<li><a id="api_mqtt"><tt>/api/mqtt</tt></a><ul>
<li>POST JSON payload to <code>/api/mqtt/your/full/topic</code></li>
<li>Payload will be published to <code>your/full/topic</code></li>
</ul>
</li>
</ul>
<h2 id="websocket-api">Websocket API</h2>
<ul>
<li><a id="api_events_intent"><tt>/api/events/intent</tt></a><ul>
<li>Emits <a href="../usage/#websocket-intents">JSON-encoded intents</a> after each NLU <a href="#nlu_query">query</a></li>
</ul>
</li>
<li><a id="api_events_text"><tt>/api/events/text</tt></a><ul>
<li>Emits <a href="../usage/#websocket-transcriptions">JSON-encoded transcriptions</a> after each ASR <a href="#asr_textcaptured">transcription</a></li>
</ul>
</li>
<li><a id="api_events_wake"><tt>/api/events/wake</tt></a><ul>
<li>Emits <a href="../usage/#websocket-wake">JSON-encoded detections</a> after each wake word <a href="#hotword_detected">detection</a></li>
</ul>
</li>
<li><a id="api_mqtt"><tt>/api/mqtt</tt></a><ul>
<li>Allows you to subscribe to, receive, and publish <a href="../usage/#websocket-mqtt-messages">JSON-encoded MQTT messages</a></li>
</ul>
</li>
</ul>
<h2 id="profile-settings">Profile Settings</h2>
<p>All available profile sections and settings are listed below:</p>
<ul>
<li><code>home_assistant</code> - how to communicate with Home Assistant/Hass.io<ul>
<li><code>url</code> - Base URL of Home Assistant server (no <code>/api</code>)</li>
<li><code>access_token</code> -  long-lived access token for Home Assistant (Hass.io token is used automatically)</li>
<li><code>api_password</code> - Password, if you have that enabled (deprecated)</li>
<li><code>pem_file</code> - Full path to your <a href="http://docs.python-requests.org/en/latest/user/advanced/#ssl-cert-verification">CA_BUNDLE file or a directory with certificates of trusted CAs</a></li>
<li><code>event_type_format</code> - Python format string used to create event type from intent type (<code>{0}</code>)</li>
</ul>
</li>
<li><code>speech_to_text</code> - transcribing <a href="../speech-to-text/">voice commands to text</a><ul>
<li><code>system</code> - name of speech to text system (<code>pocketsphinx</code>, <code>kaldi</code>, <code>remote</code>, <code>command</code>, <code>remote</code>, <code>hermes</code>, or <code>dummy</code>)</li>
<li><code>pocketsphinx</code> - configuration for <a href="../speech-to-text/#pocketsphinx">Pocketsphinx</a><ul>
<li><code>compatible</code> - true if profile can use pocketsphinx for speech recognition</li>
<li><code>acoustic_model</code> - directory with CMU 16 kHz acoustic model</li>
<li><code>base_dictionary</code> - large text file with word pronunciations (read only)</li>
<li><code>custom_words</code> - small text file with words/pronunciations added by user</li>
<li><code>dictionary</code> - text file with all words/pronunciations needed for example sentences</li>
<li><code>unknown_words</code> - small text file with guessed word pronunciations (from phonetisaurus)</li>
<li><code>language_model</code> - text file with trigram <a href="https://cmusphinx.github.io/wiki/arpaformat/">ARPA language model</a> built from example sentences</li>
<li><code>open_transcription</code> - true if general language model should be used (custom voices commands ignored)</li>
<li><code>base_language_model</code> - large general language model (read only)</li>
<li><code>mllr_matrix</code> - MLLR matrix from <a href="https://cmusphinx.github.io/wiki/tutorialtuning/">acoustic model tuning</a></li>
<li><code>mix_weight</code> - how much of the base language model to <a href="../training/#language-model-mixing">mix in during training</a> (0-1)</li>
<li><code>phoneme_examples</code> - text file with examples for each acoustic model phoneme</li>
</ul>
</li>
<li><code>kaldi</code> - configuration for <a href="../speech-to-text/#kaldi">Kaldi</a><ul>
<li><code>compatible</code> - true if profile can use Kaldi for speech recognition</li>
<li><code>kaldi_dir</code> - absolute path to Kaldi root directory</li>
<li><code>model_dir</code> - directory where Kaldi model is stored (relative to profile directory)</li>
<li><code>graph</code> - directory where HCLG.fst is located (relative to <code>model_dir</code>)</li>
<li><code>base_graph</code> - directory where large general HCLG.fst is located (relative to <code>model_dir</code>)</li>
<li><code>base_dictionary</code> - large text file with word pronunciations (read only)</li>
<li><code>custom_words</code> - small text file with words/pronunciations added by user</li>
<li><code>dictionary</code> - text file with all words/pronunciations needed for example sentences</li>
<li><code>open_transcription</code> - true if general language model should be used (custom voices commands ignored)</li>
<li><code>unknown_words</code> - small text file with guessed word pronunciations (from phonetisaurus)</li>
<li><code>mix_weight</code> - how much of the base language model to <a href="../training/#language-model-mixing">mix in during training</a> (0-1)</li>
<li><code>phoneme_examples</code> - text file with examples for each acoustic model phoneme</li>
</ul>
</li>
<li><code>remote</code> - configuration for <a href="../speech-to-text/#remote-http-server">remote Rhasspy server</a><ul>
<li><code>url</code> - URL to POST WAV data for transcription (e.g., <code>http://your-rhasspy-server:12101/api/speech-to-text</code>)</li>
</ul>
</li>
<li><code>command</code> - configuration for <a href="../speech-to-text/#command">external speech-to-text program</a><ul>
<li><code>program</code> - path to executable</li>
<li><code>arguments</code> - list of arguments to pass to program</li>
</ul>
</li>
<li><code>sentences_ini</code> - Ini file with example <a href="../training/#sentencesini">sentences/JSGF templates</a> grouped by intent</li>
<li><code>sentences_dir</code> - Directory with additional sentence templates (default: <code>intents</code>)</li>
<li><code>g2p_model</code> - finite-state transducer for phonetisaurus to guess word pronunciations</li>
<li><code>g2p_casing</code> - casing to force for g2p model (<code>upper</code>, <code>lower</code>, or blank)</li>
<li><code>dictionary_casing</code> - casing to force for dictionary words (<code>upper</code>, <code>lower</code>, or blank)</li>
<li><code>slots_dir</code> - directory to look for <a href="../training/#slots-lists">slots lists</a> (default: <code>slots</code>)</li>
<li><code>slot_programs</code> - directory to look for <a href="../training/#slot-programs">slot programs</a> (default <code>slot_programs</code>)</li>
</ul>
</li>
<li><code>intent</code> - transforming text commands to intents<ul>
<li><code>system</code> - intent recognition system (<code>fsticuffs</code>, <code>fuzzywuzzy</code>, <code>rasa</code>, <code>remote</code>, <code>adapt</code>, <code>command</code>, or <code>dummy</code>)</li>
<li><code>fsticuffs</code> - configuration for <a href="https://www.openfst.org">OpenFST-based</a> intent recognizer<ul>
<li><code>intent_json</code> - path to intent graph JSON file generated by [rhasspy-nlu][https://github.com/rhasspy/rhasspy-nlu]</li>
<li><code>converters_dir</code> - directory to look for <a href="../training/#converters">converter</a> programs (default: <code>converters</code>)</li>
<li><code>ignore_unknown_words</code> - true if words not in the FST symbol table should be ignored</li>
<li><code>fuzzy</code> - true if text is matching in a fuzzy manner, skipping words in <code>stop_words.txt</code></li>
</ul>
</li>
<li><code>fuzzywuzzy</code> - configuration for simplistic <a href="https://en.wikipedia.org/wiki/Levenshtein_distance">Levenshtein distance</a> based intent recognizer<ul>
<li><code>examples_json</code> - JSON file with intents/example sentences</li>
<li><code>min_confidence</code> - minimum confidence required for intent to be converted to a JSON event (0-1)</li>
</ul>
</li>
<li><code>remote</code> - configuration for remote Rhasspy server<ul>
<li><code>url</code> - URL to POST text to for intent recognition (e.g., <code>http://your-rhasspy-server:12101/api/text-to-intent</code>)</li>
</ul>
</li>
<li><code>rasa</code> - configuration for <a href="https://rasa.com/">Rasa NLU</a> based intent recognizer<ul>
<li><code>url</code> - URL of remote Rasa NLU server (e.g., <code>http://localhost:5005/</code>)</li>
<li><code>examples_markdown</code> - Markdown file to generate with intents/example sentences</li>
<li><code>project_name</code> - name of project to generate during training</li>
</ul>
</li>
<li><code>adapt</code> - configuration for <a href="https://github.com/MycroftAI/adapt">Mycroft Adapt</a> based intent recognizer<ul>
<li><code>stop_words</code> - text file with words to ignore in training sentences</li>
</ul>
</li>
<li><code>command</code> - configuration for external speech-to-text program<ul>
<li><code>program</code> - path to executable</li>
<li><code>arguments</code> - list of arguments to pass to program</li>
</ul>
</li>
<li><code>replace_numbers</code> if true, automatically replace number ranges (<code>N..M</code>) or numbers (<code>N</code>) with words</li>
</ul>
</li>
<li><code>text_to_speech</code> - pronouncing words<ul>
<li><code>system</code> - text to speech system (<code>espeak</code>, <code>flite</code>, <code>picotts</code>, <code>marytts</code>, <code>command</code>, <code>remote</code>, <code>hermes</code>, or <code>dummy</code>)</li>
<li><code>espeak</code> - configuration for <a href="http://espeak.sourceforge.net">eSpeak</a><ul>
<li><code>phoneme_map</code> - text file mapping CMU phonemes to eSpeak phonemes</li>
</ul>
</li>
<li><code>flite</code> - configuration for <a href="http://www.festvox.org/flite">flite</a><ul>
<li><code>voice</code> - name of voice to use (e.g., <code>kal16</code>, <code>rms</code>, <code>awb</code>)</li>
</ul>
</li>
<li><code>picotts</code> - configuration for <a href="https://en.wikipedia.org/wiki/SVOX">PicoTTS</a><ul>
<li><code>language</code> - language to use (default if not present)</li>
</ul>
</li>
<li><code>marytts</code> - configuration for <a href="http://mary.dfki.de">MaryTTS</a><ul>
<li><code>url</code> - address:port of MaryTTS server (port is usually 59125)</li>
<li><code>voice</code> - name of voice to use (e.g., <code>cmu-slt</code>). Default if not present.</li>
<li><code>locale</code> - name of locale to use (e.g., <code>en-US</code>). Default if not present.</li>
</ul>
</li>
<li><code>wavenet</code> - configuration for Google's <a href="https://cloud.google.com/text-to-speech/docs/wavenet">WaveNet</a><ul>
<li><code>cache_dir</code> - path to directory in your profile where WAV files are cached</li>
<li><code>credentials_json</code> - path to the JSON credentials file (generated online)</li>
<li><code>gender</code> - gender of speaker (<code>MALE</code> <code>FEMALE</code>)</li>
<li><code>language_code</code> - language/locale e.g. <code>en-US</code>,</li>
<li><code>sample_rate</code> - WAV sample rate (default: 22050)</li>
<li><code>url</code> - URL of WaveNet endpoint</li>
<li><code>voice</code> - voice to use (e.g., <code>Wavenet-C</code>)</li>
<li><code>fallback_tts</code> - text to speech system to use when offline or error occurs (e.g., <code>espeak</code>)</li>
</ul>
</li>
<li><code>remote</code> - configuration for remote text to speech server<ul>
<li><code>url</code> - URL to POST sentence to and get back WAV data</li>
</ul>
</li>
</ul>
</li>
<li><code>training</code> - training speech/intent recognizers<ul>
<li><code>speech_to_text</code> - training for speech decoder<ul>
<li><code>system</code> - speech to text training system (<code>auto</code> or <code>dummy</code>)</li>
<li><code>command</code> - configuration for external speech-to-text training program<ul>
<li><code>program</code> - path to executable</li>
<li><code>arguments</code> - list of arguments to pass to program</li>
</ul>
</li>
<li><code>remote</code> - configuration for external HTTP endpoint<ul>
<li><code>url</code> - URL of speech to text training endpoint</li>
</ul>
</li>
</ul>
</li>
<li><code>intent</code> - training for intent recognizer<ul>
<li><code>system</code> - intent recognizer training system (<code>auto</code> or <code>dummy</code>)</li>
<li><code>command</code> - configuration for external intent recognizer training program<ul>
<li><code>program</code> - path to executable</li>
<li><code>arguments</code> - list of arguments to pass to program</li>
</ul>
</li>
<li><code>remote</code> - configuration for external HTTP endpoint<ul>
<li><code>url</code> - URL of intent recognizer training endpoint</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><code>wake</code> - waking Rhasspy up for speech input<ul>
<li><code>system</code> - wake word recognition system (<code>pocketsphinx</code>, <code>snowboy</code>, <code>precise</code>, <code>porcupine</code>, <code>command</code>, <code>hermes</code>, or <code>dummy</code>)</li>
<li><code>pocketsphinx</code> - configuration for Pocketsphinx wake word recognizer<ul>
<li><code>keyphrase</code> - phrase to wake up on (3-4 syllables recommended)</li>
<li><code>threshold</code> - sensitivity of detection (recommended range 1e-50 to 1e-5)</li>
<li><code>chunk_size</code> - number of bytes per chunk to feed to Pocketsphinx (default 960)</li>
</ul>
</li>
<li><code>snowboy</code> - configuration for <a href="https://snowboy.kitt.ai">snowboy</a><ul>
<li><code>model</code> - path to model file(s), separated by commas (in profile directory)</li>
<li><code>sensitivity</code> - model sensitivity (0-1, default 0.5)</li>
<li><code>audio_gain</code> - audio gain (default 1)</li>
<li><code>apply_frontend</code> - true if ApplyFrontend should be set</li>
<li><code>chunk_size</code> - number of bytes per chunk to feed to snowboy (default 960)</li>
<li><code>model_settings</code> - settings for each snowboy model path (e.g., <code>snowboy/snowboy.umdl</code>)<ul>
<li><code>&lt;MODEL_PATH&gt;</code><ul>
<li><code>sensitivity</code> - model sensitivity</li>
<li><code>audio_gain</code> - audio gain</li>
<li><code>apply_frontend</code> - true if ApplyFrontend should be set</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><code>precise</code> - configuration for <a href="https://github.com/MycroftAI/mycroft-precise">Mycroft Precise</a><ul>
<li><code>engine_path</code> - path to the precise-engine binary</li>
<li><code>model</code> - path to model file (in profile directory)</li>
<li><code>sensitivity</code> - model sensitivity (0-1, default 0.5)</li>
<li><code>trigger_level</code>  - number of events to trigger activation (default 3)</li>
<li><code>chunk_size</code> - number of bytes per chunk to feed to Precise (default 2048)</li>
</ul>
</li>
<li><code>porcupine</code> - configuration for <a href="https://github.com/Picovoice/Porcupine">PicoVoice's Porcupine</a><ul>
<li><code>library_path</code> - path to  <code>libpv_porcupine.so</code> for your platform/architecture</li>
<li><code>model_path</code> - path to the <code>porcupine_params.pv</code> (lib/common)</li>
<li><code>keyword_path</code> - path to the <code>.ppn</code> keyword file</li>
<li><code>sensitivity</code> - model sensitivity (0-1, default 0.5)</li>
</ul>
</li>
<li><code>command</code> - configuration for external speech-to-text program<ul>
<li><code>program</code> - path to executable</li>
<li><code>arguments</code> - list of arguments to pass to program</li>
</ul>
</li>
</ul>
</li>
<li><code>microphone</code> - configuration for audio recording<ul>
<li><code>system</code> - audio recording system (<code>pyaudio</code>, <code>arecord</code>, gstreamer<code>, or</code>dummy`)</li>
<li><code>pyaudio</code> - configuration for <a href="https://people.csail.mit.edu/hubert/pyaudio/">PyAudio</a> microphone<ul>
<li><code>device</code> - index of device to use or empty for default device</li>
<li><code>frames_per_buffer</code> - number of frames to read at a time (default 480)</li>
</ul>
</li>
<li><code>arecord</code> - configuration for ALSA microphone<ul>
<li><code>device</code> - name of ALSA device (see <code>arecord -L</code>) to use or empty for default device</li>
<li><code>chunk_size</code> - number of bytes to read at a time (default 960)</li>
</ul>
</li>
<li><code>gstreamer</code> - configuration for GStreamer audio recorder<ul>
<li><code>pipeline</code> - GStreamer pipeline (e.g., <code>FILTER ! FILTER ! ...</code>) without sink</li>
</ul>
</li>
</ul>
</li>
<li><code>sounds</code> - configuration for audio output from Rhasspy<ul>
<li><code>system</code> - which sound output system to use (<code>aplay</code>, <code>command</code>, <code>remote</code>, <code>hermes</code>, or <code>dummy</code>)</li>
<li><code>wake</code> - path to WAV file to play when Rhasspy wakes up</li>
<li><code>recorded</code> - path to WAV file to play when a command finishes recording</li>
<li><code>aplay</code> - configuration for ALSA speakers<ul>
<li><code>device</code> - name of ALSA device (see <code>aplay -L</code>) to use or empty for default device</li>
</ul>
</li>
<li><code>command</code> - configuration for external audio output program<ul>
<li><code>program</code> - path to executable</li>
<li><code>arguments</code> - list of arguments to pass to program</li>
</ul>
</li>
<li><code>remote</code> - configuration for remote audio output server<ul>
<li><code>url</code> - URL to POST WAV data to</li>
</ul>
</li>
</ul>
</li>
<li><code>handle</code><ul>
<li><code>system</code> - which intent handling system to use (<code>hass</code>, <code>command</code>, <code>remote</code>, or <code>dummy</code>)</li>
<li><code>command</code> - configuration for external speech-to-text program<ul>
<li><code>program</code> - path to executable</li>
<li><code>arguments</code> - list of arguments to pass to program</li>
</ul>
</li>
<li><code>remote</code> - configuration for remote HTTP intent handler<ul>
<li><code>url</code> - URL to POST intent JSON to and receive response JSON from</li>
</ul>
</li>
</ul>
</li>
<li><code>mqtt</code> - configuration for MQTT<ul>
<li><code>enabled</code> - true if external broker should be used (false uses internal broker on port 12183)</li>
<li><code>host</code> - external MQTT host</li>
<li><code>port</code> - external MQTT port</li>
<li><code>username</code> - external MQTT username (blank for anonymous)</li>
<li><code>password</code> - external MQTT password</li>
<li><code>site_id</code> - one or more Hermes site IDs (comma separated). First ID is used for new messages</li>
</ul>
</li>
<li><code>dialogue</code> - configuration for Hermes dialogue manager<ul>
<li><code>system</code> - which dialogue manager to use (<code>rhasspy</code>, <code>hermes</code>, or <code>dummy</code>)</li>
</ul>
</li>
<li><code>download</code> - configuration for profile file downloading<ul>
<li><code>url_base</code> - base URL to download profile artifacts (defaults to Github)</li>
<li><code>conditions</code> - profile settings that will trigger file downloads<ul>
<li>keys are profile setting paths (e.g., <code>wake.system</code>)</li>
<li>values are dictionaries whose keys are profile settings values (e.g., <code>snowboy</code>)<ul>
<li>settings may have the form <code>&lt;=N</code> or <code>!X</code> to mean "less than or equal to N" or "not X"</li>
<li>leaf nodes are dictionaries whose keys are destination file paths and whose values reference the <code>files</code> dictionary</li>
</ul>
</li>
</ul>
</li>
<li><code>files</code> - locations, etc. of files to download<ul>
<li>keys are names of files</li>
<li>values are dictionaries with:<ul>
<li><code>url</code> - URL of file to download (appended to <code>url_base</code>)</li>
<li><code>bytes_expected</code> - number of bytes file should be after decompression</li>
<li><code>unzip</code> - <code>true</code> if file should be decompressed with <code>gunzip</code></li>
<li><code>parts</code> - list of objects representing parts of a file that should be combined with <code>cat</code><ul>
<li><code>fragment</code> - fragment appended to file URL</li>
<li><code>bytes_expected</code> - number of bytes for this part</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="command-line-tools">Command Line Tools</h2>
<ul>
<li><code>rhasspy-nlu</code></li>
<li><code>rhasspy-hermes</code></li>
<li><code>rhasspy-supervisor</code></li>
</ul>
              
            </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../development/" class="btn btn-neutral float-right" title="Development">Next <span class="icon icon-circle-arrow-right"></span></a>
      
      
        <a href="../text-to-speech/" class="btn btn-neutral" title="Text to Speech"><span class="icon icon-circle-arrow-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
  </div>

  Built with <a href="http://www.mkdocs.org">MkDocs</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
      
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" style="cursor: pointer">
    <span class="rst-current-version" data-toggle="rst-current-version">
      
      
        <span><a href="../text-to-speech/" style="color: #fcfcfc;">&laquo; Previous</a></span>
      
      
        <span style="margin-left: 15px"><a href="../development/" style="color: #fcfcfc">Next &raquo;</a></span>
      
    </span>
</div>
    <script>var base_url = '..';</script>
    <script src="../js/theme.js" defer></script>
      <script src="../search/main.js" defer></script>

</body>
</html>
